{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L6 - FM & Word2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "idy2gCCYq9gl",
        "colab_type": "code",
        "outputId": "eb618cb3-8f04-49b2-ac34-f17b25b200e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "## Action 1 - Xlearn - FM\n",
        "# !pip install xlearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xlearn as xl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import dump_svmlight_file, load_svmlight_file\n",
        "\n",
        "#Add this to avoid std::logic_error\n",
        "import os\n",
        "os.environ['USER'] = 'test' \n",
        "\n",
        "def split_data(data,train_size):\n",
        "  n = int(train_size * len(data))\n",
        "  return data[:n],data[n:]\n",
        "\n",
        "def convert_df_to_libsvm(df,f):\n",
        "  X = df.drop(columns=['rating'])\n",
        "  y = df.rating\n",
        "  dump_svmlight_file(X, y, f)\n",
        "\n",
        "## Step 1. 准备数据\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/datasets/ratings_small.txt\",usecols=['userId','movieId','rating'])\n",
        "train_data,test_data = split_data(df,0.7)\n",
        "convert_df_to_libsvm(train_data,'small_train.txt')\n",
        "convert_df_to_libsvm(test_data,'small_test.txt')\n",
        "\n",
        "\n",
        "## Step 2. Train model\n",
        "model = xl.create_fm()\n",
        "model.setTrain('./small_train.txt')\n",
        "\n",
        "param = {'task':'reg', \n",
        "         'lr':0.001, \n",
        "         'lambda':0.0002,\n",
        "         'epoch':5000,\n",
        "         'metric':'rmse',\n",
        "         'fold':10}\n",
        "\n",
        "model.setTXTModel(\"./model.txt\")\n",
        "model.fit(param, \"./model.out\")\n",
        "\n",
        "model.setTest(\"./small_test.txt\")\n",
        "model.predict(\"./model.out\", \"./output.txt\")\n",
        "\n",
        "## Step 3. Evaluate model\n",
        "y_pred = pd.read_csv(\"output.txt\",header=None)\n",
        "y_pred = np.array(y_pred).ravel()\n",
        "\n",
        "y_val = pd.read_csv(\"small_test.txt\",sep=' ',header=None)\n",
        "y_val = y_val.drop(y_val.columns[1:],axis=1)\n",
        "y_val = np.array(y_val).ravel()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "for i in range(10):\n",
        "  print(y_pred[i],\" : \",y_val[i])\n",
        "print('MSE is : %lf' % mean_squared_error(y_pred,y_val))\n",
        "print('R^2 is : %lf' % r2_score(y_pred,y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.5661300000000002  :  3.0\n",
            "3.56057  :  5.0\n",
            "3.5447900000000003  :  4.0\n",
            "3.53675  :  4.0\n",
            "3.53407  :  3.5\n",
            "3.5312699999999997  :  4.0\n",
            "3.5099400000000003  :  5.0\n",
            "3.5069  :  5.0\n",
            "3.5016  :  5.0\n",
            "3.49044  :  3.5\n",
            "MSE is : 1.086394\n",
            "R^2 is : -39.164734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vFMmO_vi7ft",
        "colab_type": "code",
        "outputId": "af3c5006-998a-41ba-ca55-0584f8dceeec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Action 2 - DeepFM\n",
        "#!pip install deepctr\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.inputs import SparseFeat,get_feature_names\n",
        "\n",
        "#数据加载\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/datasets/movielens_sample.txt\")\n",
        "sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "target = ['rating']\n",
        "\n",
        "# 对特征标签进行编码\n",
        "for feature in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    data[feature] = lbe.fit_transform(data[feature])\n",
        "\n",
        "# # 计算每个特征中的 不同特征值的个数\n",
        "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique(),embedding_dim=10) for feature in sparse_features]\n",
        "# print(fixlen_feature_columns)\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "# print(feature_names)\n",
        "\n",
        "## 将数据集切分成训练集和测试集\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train_model_input = {name:train[name].values for name in feature_names}\n",
        "test_model_input = {name:test[name].values for name in feature_names}\n",
        "\n",
        "## 使用DeepFM进行训练\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', dnn_dropout=0.1)\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=50, verbose=True, validation_split=0.2)\n",
        "## 使用DeepFM进行预测\n",
        "pred_ans = model.predict(test_model_input, batch_size=256)\n",
        "\n",
        "## 输出RMSE或MSE\n",
        "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
        "rmse = mse ** 0.5\n",
        "print(\"test RMSE\", rmse)\n",
        "r_score = round(r2_score(test[target].values, pred_ans), 4)\n",
        "print(\"test R^2\", r_score)\n",
        "\n",
        "# for i in range(30):\n",
        "#   print(test[target].values[i],pred_ans[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 323ms/step - loss: 14.6804 - mse: 14.6804 - val_loss: 13.1701 - val_mse: 13.1701\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14.5744 - mse: 14.5744 - val_loss: 13.0787 - val_mse: 13.0787\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 14.4510 - mse: 14.4510 - val_loss: 12.9804 - val_mse: 12.9804\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 14.3181 - mse: 14.3181 - val_loss: 12.8746 - val_mse: 12.8746\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14.1778 - mse: 14.1778 - val_loss: 12.7600 - val_mse: 12.7600\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 14.0172 - mse: 14.0172 - val_loss: 12.6354 - val_mse: 12.6354\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 13.8560 - mse: 13.8560 - val_loss: 12.4998 - val_mse: 12.4998\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 13.6655 - mse: 13.6655 - val_loss: 12.3522 - val_mse: 12.3522\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 13.4601 - mse: 13.4601 - val_loss: 12.1921 - val_mse: 12.1921\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13.2623 - mse: 13.2623 - val_loss: 12.0185 - val_mse: 12.0185\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13.0181 - mse: 13.0181 - val_loss: 11.8305 - val_mse: 11.8305\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 12.7757 - mse: 12.7756 - val_loss: 11.6271 - val_mse: 11.6271\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 12.4921 - mse: 12.4921 - val_loss: 11.4076 - val_mse: 11.4076\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 12.1903 - mse: 12.1902 - val_loss: 11.1710 - val_mse: 11.1710\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 11.8595 - mse: 11.8595 - val_loss: 10.9162 - val_mse: 10.9162\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11.5306 - mse: 11.5306 - val_loss: 10.6422 - val_mse: 10.6422\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11.1353 - mse: 11.1353 - val_loss: 10.3476 - val_mse: 10.3476\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 10.7035 - mse: 10.7035 - val_loss: 10.0313 - val_mse: 10.0313\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10.2935 - mse: 10.2935 - val_loss: 9.6928 - val_mse: 9.6928\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9.8729 - mse: 9.8729 - val_loss: 9.3316 - val_mse: 9.3316\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.3134 - mse: 9.3134 - val_loss: 8.9474 - val_mse: 8.9474\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 8.7700 - mse: 8.7699 - val_loss: 8.5400 - val_mse: 8.5400\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.2256 - mse: 8.2256 - val_loss: 8.1100 - val_mse: 8.1099\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.5928 - mse: 7.5928 - val_loss: 7.6579 - val_mse: 7.6579\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.9383 - mse: 6.9383 - val_loss: 7.1852 - val_mse: 7.1852\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6.4165 - mse: 6.4165 - val_loss: 6.6936 - val_mse: 6.6936\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.7784 - mse: 5.7784 - val_loss: 6.1864 - val_mse: 6.1864\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.0402 - mse: 5.0402 - val_loss: 5.6674 - val_mse: 5.6674\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.4184 - mse: 4.4183 - val_loss: 5.1408 - val_mse: 5.1408\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.6851 - mse: 3.6851 - val_loss: 4.6131 - val_mse: 4.6131\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.0939 - mse: 3.0939 - val_loss: 4.0922 - val_mse: 4.0922\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.5892 - mse: 2.5891 - val_loss: 3.5872 - val_mse: 3.5872\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.0439 - mse: 2.0439 - val_loss: 3.1086 - val_mse: 3.1086\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.6324 - mse: 1.6324 - val_loss: 2.6668 - val_mse: 2.6667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.2960 - mse: 1.2960 - val_loss: 2.2730 - val_mse: 2.2730\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.9966 - mse: 0.9966 - val_loss: 1.9371 - val_mse: 1.9371\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.0348 - mse: 1.0348 - val_loss: 1.6677 - val_mse: 1.6676\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0435 - mse: 1.0434 - val_loss: 1.4674 - val_mse: 1.4673\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.1071 - mse: 1.1070 - val_loss: 1.3292 - val_mse: 1.3292\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.2201 - mse: 1.2200 - val_loss: 1.2425 - val_mse: 1.2425\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.3618 - mse: 1.3617 - val_loss: 1.1959 - val_mse: 1.1959\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.4114 - mse: 1.4113 - val_loss: 1.1788 - val_mse: 1.1788\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3999 - mse: 1.3998 - val_loss: 1.1860 - val_mse: 1.1860\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.4268 - mse: 1.4267 - val_loss: 1.2187 - val_mse: 1.2186\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.2056 - mse: 1.2056 - val_loss: 1.2758 - val_mse: 1.2757\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.9625 - mse: 0.9624 - val_loss: 1.3573 - val_mse: 1.3572\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.8096 - mse: 0.8096 - val_loss: 1.4623 - val_mse: 1.4623\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6306 - mse: 0.6305 - val_loss: 1.5879 - val_mse: 1.5879\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5155 - mse: 0.5155 - val_loss: 1.7273 - val_mse: 1.7272\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3758 - mse: 0.3758 - val_loss: 1.8743 - val_mse: 1.8742\n",
            "test RMSE 1.3991425945914162\n",
            "test R^2 -0.4039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7kpL7bE6cGJ",
        "colab_type": "code",
        "outputId": "5a20dff6-9a33-4865-829f-948c0b8f54f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "## Action 3 - Word2Vec\n",
        "# -*-coding: utf-8 -*-\n",
        "# 对txt文件进行中文分词\n",
        "import jieba.analyse\n",
        "from jieba import posseg as psg\n",
        "import os\n",
        "from gensim import models\n",
        "from gensim.test.utils import datapath\n",
        "from gensim import utils\n",
        "import smart_open\n",
        "from time import time\n",
        "\n",
        "## Step1. Prepare text data\n",
        "def cut_words(file,out_name,stopwords,noun_only=False):\n",
        "  with open(file, 'rb') as f:\n",
        "      document = f.read()\n",
        "      print(document)\n",
        "      t1 = time()\n",
        "      \n",
        "      if noun_only:\n",
        "      #Option 2 只读取人名词汇，用来做下面的fitler\n",
        "        allow_pos = ('nr','PER') \n",
        "        document_cut = jieba.analyse.extract_tags(document, topK=100000, withWeight=False, allowPOS=allow_pos)\n",
        "      else:\n",
        "      #Option 1 读取所有词汇\n",
        "        document_cut = jieba.cut(document)\n",
        "      \n",
        "      sentence_segment=[]\n",
        "      for word in document_cut:\n",
        "          if word not in stopwords:\n",
        "              sentence_segment.append(word)\n",
        "      \n",
        "      #Write files  \n",
        "      result = ' '.join(sentence_segment)\n",
        "      result = result.encode('utf-8')\n",
        "      with open(out_name, 'wb') as f2:\n",
        "          f2.write(result)\n",
        "      f.close()\n",
        "      print(time()-t1)\n",
        "\n",
        "stopwords = ['却说','不可','如此','不能','如何','于是','今日','次日','何不','何故','不如','正是','可以']\n",
        "file = '/content/drive/My Drive/Colab Notebooks/datasets/three_kingdoms.txt'\n",
        "# cut_words(file,'./three_kingdoms_segment.txt',stopwords,noun_only=False)  #This is the full text for training\n",
        "# cut_words(file,'./three_kingdoms_segment_noun.txt',stopwords,noun_only=True)  #This is the nouns used for filtering\n",
        "\n",
        "\n",
        "# ## Step 2. Build Model\n",
        "## A memory-friendly way to read large corpus\n",
        "class MyCorpus(object):\n",
        "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
        "\n",
        "    def __iter__(self):\n",
        "        corpus_path = datapath('/content/three_kingdoms_segment.txt')\n",
        "        for line in smart_open.open(corpus_path):\n",
        "            # assume there's one document per line, tokens separated by whitespace\n",
        "            yield utils.simple_preprocess(line)\n",
        "\n",
        "# sentences = MyCorpus()\n",
        "# model = models.Word2Vec(\n",
        "#     sentences=sentences,\n",
        "#     size=200,  #Embeddding Dimension\n",
        "#     window = 20, \n",
        "#     min_count=2,\n",
        "#     compute_loss=True,\n",
        "#     sg=0, #0 = CBOW, 1 = Skip-Gram\n",
        "#     hs=0, \n",
        "#     negative=5,\n",
        "#     workers=4,\n",
        "#     seed=42)\n",
        "# model.save('three-kingdoms')\n",
        "\n",
        "## Load Model\n",
        "### 张飞+曹操-刘备 != 曹营猛将，感觉不太好###\n",
        "model = models.Word2Vec.load('three-kingdoms')\n",
        "print('model train loss: ',model.get_latest_training_loss())\n",
        "print('出现最多的词汇：',model.wv.index2entity[:100]) #print the most frequent 100 words\n",
        "print(model.wv.similarity('曹操','玄德')) #print similarity between words\n",
        "print('与袁绍最近似10个词：',model.wv.most_similar(positive=['袁绍'],topn=10)) #袁绍？？\n",
        "print('\\n','#'*25,'全部词汇的相似词汇 - 看起来很奇怪，逻辑不清晰','#'*25)\n",
        "print('曹操+刘备-张飞:',model.wv.most_similar(positive=['曹操','刘备'],negative=['张飞'])) #曹操+刘备-张飞\n",
        "print('张飞+曹操-刘备:',model.wv.most_similar(positive=['张飞','曹操'],negative=['刘备'])) #张飞+曹操-刘备 != 曹营猛将?\n",
        "print('孔明+孙权-曹操:',model.wv.most_similar(positive=['孔明','孙权'],negative=['曹操'])) #孔明+孙权-曹操 != 东吴谋士？\n",
        "\n",
        "\n",
        "### 如果我们仅看人名，是不是能得到张飞-刘备+曹操=魏将？ 试试看 ###\n",
        "print('\\n','#'*25,'人名only的相似词汇-看起来清楚很多','#'*25)\n",
        "\n",
        "##人词fitler\n",
        "def name_filter(words):\n",
        "  file = smart_open.open('/content/three_kingdoms_segment_noun.txt')\n",
        "  nouns_filter = next(file).split(' ')\n",
        "  words_filtered = [[word,weight] for word,weight in words if word in nouns_filter]\n",
        "  return words_filtered\n",
        "\n",
        "words = model.wv.most_similar(positive=['张飞','曹操'],negative=['刘备'],topn=100)\n",
        "words_filtered = name_filter(words)\n",
        "print('张飞+曹操-刘备: - 魏延，庞德，黄忠，夏侯都是还可以的答案')\n",
        "print(words_filtered)\n",
        "\n",
        "words = model.wv.most_similar(positive=['孔明','孙权'],negative=['曹操'],topn=100)\n",
        "words_filtered = name_filter(words)\n",
        "print('孔明+孙权-曹操: - 这个结果还挺好，东吴/其他势力军师类人物排名靠前')\n",
        "print(words_filtered)\n",
        "\n",
        "\n"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model train loss:  648674.3125\n",
            "出现最多的词汇： ['曹操', '孔明', '将军', '玄德', '关公', '丞相', '二人', '荆州', '孔明曰', '玄德曰', '张飞', '商议', '主公', '军士', '吕布', '左右', '军马', '引兵', '刘备', '大喜', '孙权', '云长', '天下', '赵云', '东吴', '不敢', '魏兵', '陛下', '司马懿', '人马', '都督', '周瑜', '一人', '不知', '汉中', '众将', '只见', '后主', '袁绍', '蜀兵', '马超', '大叫', '上马', '魏延', '此人', '先主', '太守', '天子', '后人', '背后', '黄忠', '一面', '城中', '忽报', '大军', '先生', '然后', '先锋', '夫人', '诸葛亮', '姜维', '赶来', '原来', '令人', '江东', '徐州', '忽然', '下马', '喊声', '因此', '成都', '百姓', '未知', '大败', '大事', '之后', '一军', '不见', '起兵', '马岱', '接应', '引军', '军中', '进兵', '庞德', '孟获', '大怒', '心中', '正文', '以为', '分节', '阅读', '大惊', '不得', '刘表', '下文', '追赶', '粮草', '一声', '分解']\n",
            "0.9999775\n",
            "与袁绍最近似10个词： [('曹操', 0.9999960660934448), ('大喜', 0.9999946355819702), ('不肯', 0.9999943971633911), ('然后', 0.9999943971633911), ('诸葛亮', 0.9999942779541016), ('商议', 0.9999942183494568), ('朝廷', 0.9999938607215881), ('天子', 0.9999935626983643), ('之计', 0.9999934434890747), ('以为', 0.9999934434890747)]\n",
            "\n",
            " ######################### 全部词汇的相似词汇 - 看起来很奇怪，逻辑不清晰 #########################\n",
            "曹操+刘备-张飞: [('荆州', 0.9999173879623413), ('主公', 0.9999009370803833), ('孔明曰', 0.9998867511749268), ('东吴', 0.9998754262924194), ('鲁肃', 0.9998621940612793), ('江东', 0.9998611211776733), ('兴兵', 0.9998608231544495), ('西川', 0.9998566508293152), ('孙权', 0.9998565912246704), ('张昭', 0.9998565912246704)]\n",
            "张飞+曹操-刘备: [('赶来', 0.999962329864502), ('喊声', 0.9999600052833557), ('背后', 0.9999582767486572), ('一彪', 0.9999582171440125), ('杀来', 0.9999528527259827), ('为首', 0.9999510049819946), ('魏延', 0.9999463558197021), ('前面', 0.9999459981918335), ('两下', 0.9999456405639648), ('乃是', 0.9999445676803589)]\n",
            "孔明+孙权-曹操: [('鲁肃', 0.9999901652336121), ('江东', 0.9999872446060181), ('先生', 0.9999870657920837), ('东吴', 0.9999861717224121), ('大事', 0.9999848008155823), ('此人', 0.9999842643737793), ('西川', 0.9999839067459106), ('天下', 0.9999833703041077), ('若何', 0.9999830722808838), ('汉中', 0.9999819993972778)]\n",
            "\n",
            " ######################### 人名only的相似词汇-看起来清楚很多 #########################\n",
            "张飞+曹操-刘备: - 魏延，庞德，黄忠，夏侯都是还可以的答案\n",
            "[['魏延', 0.9999463558197021], ['赵云', 0.9999325275421143], ['魏兵', 0.9999308586120605], ['庞德', 0.9999284744262695], ['黄忠', 0.9999281764030457], ['张苞', 0.9999229907989502], ['夏侯渊', 0.9999221563339233], ['王平', 0.9999211430549622], ['曹兵', 0.9999192357063293], ['张嶷', 0.9999188184738159], ['徐晃', 0.9999184608459473], ['许褚', 0.99991774559021], ['马超', 0.9999167919158936], ['曹洪', 0.999914824962616], ['伏兵', 0.9999134540557861], ['曹军', 0.999913215637207]]\n",
            "孔明+孙权-曹操: - 这个结果还挺好，东吴/其他势力军师类人物排名靠前\n",
            "[['鲁肃', 0.9999901652336121], ['玄德曰', 0.9999809861183167], ['周瑜', 0.9999806880950928], ['刘表', 0.9999804496765137], ['文武', 0.9999802112579346], ['刘璋', 0.9999794363975525], ['吴侯', 0.9999793767929077], ['诸葛亮', 0.9999793171882629], ['庞统', 0.9999783635139465], ['孔明笑', 0.9999771118164062], ['诸葛', 0.9999769926071167], ['大将军', 0.9999769330024719], ['曹丕', 0.9999763369560242], ['司马懿', 0.9999760389328003], ['袁绍', 0.9999758005142212], ['孔明曰', 0.9999749660491943]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}